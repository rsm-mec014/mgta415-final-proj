{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import nltk\n",
        "# import ssl\n",
        "\n",
        "# try:\n",
        "#     _create_unverified_https_context = ssl._create_unverified_context\n",
        "# except AttributeError:\n",
        "#     pass\n",
        "# else:\n",
        "#     ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "# nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hplnxkhuYNQC",
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:992)>\n",
            "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:992)>\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import os\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/Users/wenpuzhang/Downloads/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['text'] = data['review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "# Splitting the training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    data,  # Your feature vectors\n",
        "    data[\"label\"],  # The true labels\n",
        "    test_size=0.2,  # Specifies the proportion of data to include in the validation set\n",
        "    random_state=42  # Ensures reproducibility\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H6n9Vxh2YNQE"
      },
      "outputs": [],
      "source": [
        "# A function used to build a vocabulary based on descending word frequencies\n",
        "def build_vocab(sentences):\n",
        "    # Build vocabulary\n",
        "    word_counts = Counter(itertools.chain(*sentences))\n",
        "    # Mapping from index to word\n",
        "    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
        "    # Mapping from word to index\n",
        "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "    return word_counts, vocabulary, vocabulary_inv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5gV-kz2wYNQF"
      },
      "outputs": [],
      "source": [
        "def preprocess_df(df):\n",
        "    # get English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.add('would')\n",
        "    # prepare translation table to translate punctuation to space\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    preprocessed_sentences = []\n",
        "    for i, row in df.iterrows():\n",
        "        sent = row[\"text\"]\n",
        "        sent_nopuncts = sent.translate(translator)\n",
        "        words_list = sent_nopuncts.strip().split()\n",
        "        filtered_words = [word for word in words_list if word not in stop_words and len(word) != 1] # also skip space from above translation\n",
        "        preprocessed_sentences.append(\" \".join(filtered_words))\n",
        "    df[\"text\"] = preprocessed_sentences\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train[\"text\"] = X_train[\"review\"]\n",
        "X_val[\"text\"] = X_val[\"review\"]\n",
        "df_train = preprocess_df(X_train)\n",
        "df_test = preprocess_df(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10515, 63), (10515,))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10515, 63), (2629, 63))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import PorterStemmer \n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "ps = PorterStemmer() \n",
        "\n",
        "# return a list of tokens\n",
        "def pre_processing_by_nltk(doc, stemming = True, need_sent = False):\n",
        "    # remove non-words\n",
        "    doc = re.sub(r'[^\\w\\s]', '', doc)\n",
        "    # get sentences\n",
        "    sentences = sent_tokenize(doc)\n",
        "    # get tokens\n",
        "    tokens = []\n",
        "    for sent in sentences:\n",
        "        words = word_tokenize(sent)\n",
        "        # step 3 (optional): stemming\n",
        "        if stemming:\n",
        "            words = [ps.stem(word) for word in words]\n",
        "        if need_sent:\n",
        "            tokens.append(words)\n",
        "        else:\n",
        "            tokens += words\n",
        "    return [w.lower() for w in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wenpuzhang/Library/Python/3.11/lib/python/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Initialize TfidfVectorizer with your custom tokenizer\n",
        "tfidf = TfidfVectorizer(strip_accents=None,\n",
        "                        lowercase=True,\n",
        "                        preprocessor=None,  # Assuming preprocessing is already done\n",
        "                        tokenizer=pre_processing_by_nltk,  # Use your custom tokenizer\n",
        "                        use_idf=True,\n",
        "                        norm='l2',\n",
        "                        smooth_idf=True,\n",
        "                        min_df = 2,\n",
        "                        max_df = 0.98,\n",
        "                        ngram_range=(1, 3)\n",
        "                        )\n",
        "\n",
        "# Fit and transform the training data to create the training vectors\n",
        "train_vec = tfidf.fit_transform(df_train[\"text\"])\n",
        "test_vec = tfidf.transform(df_test[\"text\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10515, 515814)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10515,)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf1 = LogisticRegression(max_iter=1000000000, \n",
        "                           random_state=42, \n",
        "                           multi_class= \"auto\",\n",
        "                            C = 10 ,\n",
        "                            warm_start= True)\n",
        "# Fit the model on the new training set\n",
        "clf1.fit(train_vec, y_train_encoded)\n",
        "\n",
        "# Predict on the validation set\n",
        "val_preds = clf1.predict(test_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro-average F1 score: 0.7181248242859979\n",
            "Micro-average F1 score: 0.799923925446938\n",
            "Weighted-average F1 score: 0.7833277133508931\n"
          ]
        }
      ],
      "source": [
        "macro_f1 = f1_score(y_val_encoded, val_preds, average='macro')\n",
        "micro_f1 = f1_score(y_val_encoded, val_preds, average='micro')\n",
        "weighted_f1 = f1_score(y_val_encoded, val_preds, average='weighted')\n",
        "print(f'Macro-average F1 score: {macro_f1}')\n",
        "print(f'Micro-average F1 score: {micro_f1}')\n",
        "print(f'Weighted-average F1 score: {weighted_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7649296310384176\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_val_encoded, val_preds)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set a random seed\n",
        "random_seed = 42\n",
        "random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoding = tokenizer.batch_encode_plus(\n",
        "    X_train['text'],                    # List of input texts\n",
        "    padding=True,              # Pad to the maximum sequence length\n",
        "    truncation=True,           # Truncate to the maximum sequence length if necessary\n",
        "    return_tensors='pt',      # Return PyTorch tensors\n",
        "    add_special_tokens=True    # Add special tokens CLS and SEP\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input ID: tensor([[  101,  7842, 16475,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2253,  ...,     0,     0,     0],\n",
            "        [  101,  2204, 21122,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2026,  2564,  ...,     0,     0,     0],\n",
            "        [  101,  2023,  2173,  ...,     0,     0,     0],\n",
            "        [  101, 12090,  4840,  ...,     0,     0,     0]])\n",
            "Attention mask: tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "input_ids = encoding['input_ids']  # Token IDs\n",
        "# print input IDs\n",
        "print(f\"Input ID: {input_ids}\")\n",
        "attention_mask = encoding['attention_mask']\n",
        "print(f\"Attention mask: {attention_mask}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10515, 512])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determine the batch size\n",
        "batch_size = 5 \n",
        "\n",
        "# Initialize an empty list to hold the embeddings\n",
        "word_embeddings = []\n",
        "\n",
        "# Process in batches\n",
        "for i in range(0, len(input_ids), batch_size):\n",
        "    # Get the batch\n",
        "    batch_input_ids = input_ids[i:i+batch_size]\n",
        "    batch_attention_mask = attention_mask[i:i+batch_size]\n",
        "    \n",
        "    # Perform the forward pass and get the embeddings\n",
        "    with torch.no_grad():\n",
        "        batch_outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        batch_word_embeddings = batch_outputs.last_hidden_state\n",
        "        word_embeddings.append(batch_word_embeddings)\n",
        "\n",
        "\n",
        "word_embeddings = torch.cat(word_embeddings, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode the test data\n",
        "test_encoding = tokenizer.batch_encode_plus(\n",
        "    X_val['text'],                  # List of input texts from the test set\n",
        "    padding=True,                    # Pad to the maximum sequence length\n",
        "    truncation=True,                 # Truncate to the maximum sequence length if necessary\n",
        "    return_tensors='pt',             # Return PyTorch tensors\n",
        "    add_special_tokens=True          # Add special tokens CLS and SEP\n",
        ")\n",
        "\n",
        "test_input_ids = test_encoding['input_ids']\n",
        "test_attention_mask = test_encoding['attention_mask']\n",
        "\n",
        "# Generate embeddings for the test set\n",
        "test_word_embeddings = []\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(test_input_ids), batch_size):\n",
        "        batch_input_ids = test_input_ids[i:i+batch_size]\n",
        "        batch_attention_mask = test_attention_mask[i:i+batch_size]\n",
        "        batch_outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        batch_word_embeddings = batch_outputs.last_hidden_state\n",
        "        test_word_embeddings.append(batch_word_embeddings)\n",
        "\n",
        "# Concatenate all batches into one tensor for the test set\n",
        "test_word_embeddings = torch.cat(test_word_embeddings, dim=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = len(set(y_train_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wenpuzhang/Library/Python/3.11/lib/python/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "# Assuming X_train is your input features matrix with shape [n_samples, n_features]\n",
        "input_dim = 768  # For BERT embeddings, this would be 768. Adjust according to your feature size\n",
        "\n",
        "model = Sequential([\n",
        "    # First hidden layer\n",
        "    Dense(512, activation='relu', input_shape=(input_dim,)),  # Increased to 512 units\n",
        "    Dropout(0.5),\n",
        "    # Second hidden layer\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    # Third hidden layer\n",
        "    # Dense(256, activation='relu'),\n",
        "    # Dropout(0.5),\n",
        "    # Fourth hidden layer\n",
        "    # Dense(, activation='relu'),\n",
        "    # Dropout(0.5),\n",
        "    # Output layer\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adamax\n",
        "# Define your custom learning rate\n",
        "custom_learning_rate = 0.001\n",
        "# Initialize the Adamax optimizer with your custom learning rate\n",
        "optimizer = Adamax(learning_rate=custom_learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2391 - loss: 2.1266 - val_accuracy: 0.5563 - val_loss: 1.5057\n",
            "Epoch 2/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4914 - loss: 1.5378 - val_accuracy: 0.6334 - val_loss: 1.1374\n",
            "Epoch 3/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5800 - loss: 1.2490 - val_accuracy: 0.6695 - val_loss: 0.9851\n",
            "Epoch 4/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 1.1195 - val_accuracy: 0.6795 - val_loss: 0.9460\n",
            "Epoch 5/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 1.0536 - val_accuracy: 0.6971 - val_loss: 0.9009\n",
            "Epoch 6/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6603 - loss: 1.0008 - val_accuracy: 0.6966 - val_loss: 0.8707\n",
            "Epoch 7/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6754 - loss: 0.9579 - val_accuracy: 0.7214 - val_loss: 0.8322\n",
            "Epoch 8/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6730 - loss: 0.9392 - val_accuracy: 0.7185 - val_loss: 0.8358\n",
            "Epoch 9/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.9045 - val_accuracy: 0.7309 - val_loss: 0.8191\n",
            "Epoch 10/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.9076 - val_accuracy: 0.7389 - val_loss: 0.8235\n",
            "Epoch 11/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.8747 - val_accuracy: 0.7328 - val_loss: 0.7943\n",
            "Epoch 12/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7051 - loss: 0.8724 - val_accuracy: 0.7271 - val_loss: 0.8022\n",
            "Epoch 13/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7134 - loss: 0.8589 - val_accuracy: 0.7356 - val_loss: 0.7909\n",
            "Epoch 14/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.8358 - val_accuracy: 0.7461 - val_loss: 0.7924\n",
            "Epoch 15/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.8302 - val_accuracy: 0.7470 - val_loss: 0.7849\n",
            "Epoch 16/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.8089 - val_accuracy: 0.7475 - val_loss: 0.7580\n",
            "Epoch 17/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.8055 - val_accuracy: 0.7513 - val_loss: 0.7616\n",
            "Epoch 18/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.8067 - val_accuracy: 0.7423 - val_loss: 0.7775\n",
            "Epoch 19/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.8026 - val_accuracy: 0.7523 - val_loss: 0.7621\n",
            "Epoch 20/20\n",
            "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.7721 - val_accuracy: 0.7523 - val_loss: 0.7687\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_vec, y_train_encoded,\n",
        "                    batch_size=10,\n",
        "                    epochs=20,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step\n",
            "Macro-average F1 score: 0.615314399931103\n",
            "Micro-average F1 score: 0.7402054012932675\n",
            "Weighted-average F1 score: 0.7135849007048611\n",
            "Accuracy: 0.7402054012932674\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(test_vec)\n",
        "predictions = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Calculate F1 score\n",
        "macro_f1 = f1_score(y_val_encoded, predictions, average='macro')\n",
        "micro_f1 = f1_score(y_val_encoded, predictions, average='micro')\n",
        "weighted_f1 = f1_score(y_val_encoded, predictions, average='weighted')\n",
        "\n",
        "print(f'Macro-average F1 score: {macro_f1}')\n",
        "print(f'Micro-average F1 score: {micro_f1}')\n",
        "print(f'Weighted-average F1 score: {weighted_f1}')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val_encoded, predictions)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LOGISTIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Average the embeddings across the sequence length for training set\n",
        "train_vec = torch.mean(word_embeddings, dim=1).cpu().numpy()\n",
        "\n",
        "# Average the embeddings across the sequence length for test set\n",
        "test_vec = torch.mean(test_word_embeddings, dim=1).cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10515, 768)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2629, 768)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf2 = LogisticRegression(max_iter=1000000000, \n",
        "                           random_state=42, \n",
        "                           multi_class= \"auto\",\n",
        "                            C = 10 ,\n",
        "                            warm_start= True)\n",
        "# Fit the model on the new training set\n",
        "clf2.fit(train_vec, y_train_encoded)\n",
        "\n",
        "# Predict on the validation set\n",
        "val_preds = clf2.predict(test_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro-average F1 score: 0.6910020482664272\n",
            "Micro-average F1 score: 0.7649296310384177\n",
            "Weighted-average F1 score: 0.7563900028673805\n"
          ]
        }
      ],
      "source": [
        "macro_f1 = f1_score(y_val_encoded, val_preds, average='macro')\n",
        "micro_f1 = f1_score(y_val_encoded, val_preds, average='micro')\n",
        "weighted_f1 = f1_score(y_val_encoded, val_preds, average='weighted')\n",
        "print(f'Macro-average F1 score: {macro_f1}')\n",
        "print(f'Micro-average F1 score: {micro_f1}')\n",
        "print(f'Weighted-average F1 score: {weighted_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7649296310384176\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "accuracy = accuracy_score(y_val_encoded, val_preds)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
